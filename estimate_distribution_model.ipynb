{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "from matplotlib import style\n",
    "from pandas_datareader import data\n",
    "import random\n",
    "from SALib.sample import latin\n",
    "from functions.stylizedfacts import *\n",
    "import scipy.stats as stats\n",
    "from functions.evolutionaryalgo import *\n",
    "from pandas_datareader import data\n",
    "from functions.helpers import hurst, organise_data, div_by_hundred, discounted_value_cash_flow, find_horizon, calculate_npv\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate model\n",
    "Following the procedure presented by [Franke & Westerhoff (2012)](https://www.sciencedirect.com/science/article/pii/S0165188912000802).\n",
    "\n",
    "## 1 Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2008-12-31' #1933\n",
    "end_date = '2018-12-31'\n",
    "\n",
    "spy_nom_price = data.DataReader(\"SP500\", \n",
    "                       start=start_date, \n",
    "                       end=end_date, \n",
    "                       data_source='fred')[\"SP500\"].dropna()\n",
    "spy_nom_returns = spy_nom_price.pct_change()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Bootstrap data for both short and long-term moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_block_size = 250 # 250\n",
    "large_block_size = 625 # 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Small data blocks returns**\n",
    "For short term moments, I produce a bootstrapped series of 250 day (= 1 year) data blocks. This means that there are 25 unique blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_blocks = []\n",
    "for x in range(0, len(spy_nom_returns), small_block_size):\n",
    "    small_data_blocks.append(list(spy_nom_returns[x:x+small_block_size]))\n",
    "    \n",
    "# draw 5000 random series\n",
    "bootstrapped_small_series = []\n",
    "for i in range(5000):\n",
    "    sim_data = [random.choice(small_data_blocks) for _ in small_data_blocks]\n",
    "    sim_data2 = [j for i in sim_data for j in i]\n",
    "    bootstrapped_small_series.append(sim_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Large data blocks returns**\n",
    "\n",
    "For the longer moments, I produce a bootstrapped series of data blocks of 625 days. To accomodate this, I cut the data set with 250 observations, to 6000 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_blocks = []\n",
    "for x in range(0, len(spy_nom_returns), large_block_size): # used to be len(spy_nom_returns[:-250])\n",
    "    large_data_blocks.append(list(spy_nom_returns[x:x+large_block_size]))\n",
    "    \n",
    "# draw 5000 random series\n",
    "bootstrapped_long_series = []\n",
    "for i in range(5000):\n",
    "    sim_data = [random.choice(large_data_blocks) for _ in large_data_blocks]\n",
    "    sim_data2 = [j for i in sim_data for j in i]\n",
    "    bootstrapped_long_series.append(sim_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Choose moments\n",
    "\n",
    "For returns, I use the following moments **short-term moments**: \n",
    "\n",
    "1. mean first-order autocorrelation of the raw returns (no predictability),\n",
    "2. autocorrelations at lags t ¼ 1\n",
    "3. autocorrelations at lags t ¼ 5\n",
    "4. mean first-order autocorrelation of the of the absolute returns (volatility clustering),\n",
    "5. Kurtosis (fat tails), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_order_autocors = []\n",
    "mean_abs_autocor = []\n",
    "autocors1 = []\n",
    "autocors5 = []\n",
    "kurtoses = []\n",
    "for rets in bootstrapped_small_series:\n",
    "    first_order_autocors.append(autocorrelation_returns(rets, 25))\n",
    "    mean_abs_autocor.append(autocorrelation_abs_returns(rets, 25))\n",
    "    rets = pd.Series(rets)\n",
    "    autocors1.append(rets.autocorr(lag=1))\n",
    "    autocors5.append(rets.autocorr(lag=5))\n",
    "    kurtoses.append(kurtosis(rets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For long-term moments, I use the autocorrelation of returns for the with lags (10, 25, 50, 100, 150 and 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_abs_auto10 = []\n",
    "spy_abs_auto25 = []\n",
    "spy_abs_auto50 = []\n",
    "spy_abs_auto100 = []\n",
    "spy_abs_auto150 = []\n",
    "spy_abs_auto200 = []\n",
    "\n",
    "for rets in bootstrapped_long_series:\n",
    "    rets = pd.Series(rets)\n",
    "    spy_abs_auto10.append(rets.abs().autocorr(lag=10))\n",
    "    spy_abs_auto25.append(rets.abs().autocorr(lag=25))\n",
    "    spy_abs_auto50.append(rets.abs().autocorr(lag=50))\n",
    "    spy_abs_auto100.append(rets.abs().autocorr(lag=100))\n",
    "    spy_abs_auto150.append(rets.abs().autocorr(lag=150))\n",
    "    spy_abs_auto200.append(rets.abs().autocorr(lag=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bootstrapped_moments = [first_order_autocors,\n",
    "                            autocors1,\n",
    "                            autocors5,\n",
    "                            mean_abs_autocor,\n",
    "                            kurtoses,\n",
    "                            spy_abs_auto10,\n",
    "                            spy_abs_auto25,\n",
    "                            spy_abs_auto50,\n",
    "                            spy_abs_auto100,\n",
    "                            spy_abs_auto150,\n",
    "                            spy_abs_auto200\n",
    "                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the t-critical value**\n",
    "def confidence_interval(sample, emp_value):\n",
    "    \"\"\"Calculate confidence_interval in sample\"\"\"\n",
    "    z_critical = stats.norm.ppf(q = 0.99)\n",
    "    stdev = pd.Series(sample).std()\n",
    "    margin_of_error = z_critical * stdev\n",
    "    confidence_interval = (emp_value - margin_of_error, emp_value + margin_of_error)  \n",
    "    return confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_bootstraps_moments(full_series, bootstrap_number):\n",
    "    \"\"\"Get a vector with the moments of a specific bootstrap\"\"\"\n",
    "    return np.array([full_series[i][bootstrap_number] for i in range(len(full_series))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_moments = [np.mean(x) for x in all_bootstrapped_moments]\n",
    "moments_b = [get_specific_bootstraps_moments(all_bootstrapped_moments, n) for n in range(len(bootstrapped_long_series))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.009590142288147235,\n",
       " -0.053186232819994565,\n",
       " -0.06599977989787965,\n",
       " 0.19067785131262055,\n",
       " 4.664644807691542,\n",
       " 0.22032722499815627,\n",
       " 0.12291300355839241,\n",
       " 0.06404942852887105,\n",
       " 0.005154107179098744,\n",
       " 0.02923536866422375,\n",
       " 0.011158749795494532]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Estimate weighting matrix:\n",
    "\n",
    "Here, I follow [Franke & Westerhoff 2016](https://link.springer.com/article/10.1007/s11403-014-0140-6#Sec8) in that I use the inverse of the bootstrap estimate of the moment covariance matrix as my weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_moments = np.array([\n",
    "        autocorrelation_returns(spy_nom_returns, 25),\n",
    "        spy_nom_returns.autocorr(lag=1),\n",
    "        spy_nom_returns.autocorr(lag=5),\n",
    "        autocorrelation_abs_returns(spy_nom_returns, 25),\n",
    "        kurtosis(spy_nom_returns),\n",
    "        spy_nom_returns.abs().autocorr(lag=10),\n",
    "        spy_nom_returns.abs().autocorr(lag=25),\n",
    "        spy_nom_returns.abs().autocorr(lag=50),\n",
    "        spy_nom_returns.abs().autocorr(lag=100),\n",
    "        spy_nom_returns.abs().autocorr(lag=150),\n",
    "        spy_nom_returns.abs().autocorr(lag=200)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.74066270e-03, -5.33776990e-02, -6.66910229e-02,  2.10895461e-01,\n",
       "        4.97365239e+00,  2.30863270e-01,  1.38701437e-01,  7.70690242e-02,\n",
       "        3.67428481e-02,  4.59816817e-02,  2.60152688e-03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent NA errors\n",
    "spy_abs_auto50 = list(pd.Series(spy_abs_auto50).fillna(0))\n",
    "spy_abs_auto100 = list(pd.Series(spy_abs_auto100).fillna(0))\n",
    "spy_abs_auto150 = list(pd.Series(spy_abs_auto150).fillna(0))\n",
    "spy_abs_auto200 = list(pd.Series(spy_abs_auto200).fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I estimate the moment covariance matrix of the bootstrapped data as: \n",
    "\n",
    "$\\hat{W} = \\frac{1}{B} \\sum{(m^b - \\hat{m})(m^b - \\hat{m})'}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hat = 1.0 / len(bootstrapped_long_series) * sum([np.dot(np.array([(mb - av_moments)]).transpose(), np.array([(mb - av_moments)])) for mb in moments_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And take the inverse so that \n",
    "\n",
    "$W = \\hat{W}^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.linalg.inv(W_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weighting matrix\n",
    "np.save('distr_weighting_matrix', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.81465475e+05, -2.64829749e+04, -9.25200729e+03,\n",
       "        -1.99887686e+04,  7.94996677e+02, -3.17697747e+02,\n",
       "         6.04248599e+02, -6.88767257e+01, -5.47611936e+02,\n",
       "         6.50115515e+02, -2.12910702e+01],\n",
       "       [-2.64829749e+04,  6.60452261e+03, -1.47353148e+03,\n",
       "         2.73008315e+03, -5.36742011e+01,  4.90536671e+01,\n",
       "        -4.53870180e+01, -1.04242066e+01,  3.39610426e+01,\n",
       "        -3.89302874e+01,  3.93909503e+01],\n",
       "       [-9.25200729e+03, -1.47353148e+03,  2.04288931e+03,\n",
       "        -4.91690500e+01, -7.48703816e+00,  3.45701629e+01,\n",
       "         1.26220576e+01, -1.78545409e+01,  3.44605163e+01,\n",
       "         3.12484613e+01, -4.30126911e+01],\n",
       "       [-1.99887686e+04,  2.73008315e+03, -4.91690500e+01,\n",
       "         3.05977123e+03, -9.08029955e+01,  3.54822578e+01,\n",
       "        -7.84199612e+01,  5.22858210e+01, -1.85786499e+00,\n",
       "         1.90173697e+00, -4.06171649e+00],\n",
       "       [ 7.94996677e+02, -5.36742011e+01, -7.48703816e+00,\n",
       "        -9.08029955e+01,  4.23992445e+00,  1.36164026e+00,\n",
       "         1.96375474e+00, -2.52491383e+00,  2.69195514e-01,\n",
       "         1.23602502e+00, -4.02332568e-01],\n",
       "       [-3.17697747e+02,  4.90536671e+01,  3.45701629e+01,\n",
       "         3.54822578e+01,  1.36164026e+00,  1.01907803e+04,\n",
       "        -3.69034959e+03, -5.11583502e+03,  6.06046581e+03,\n",
       "        -2.27793195e+03, -1.14494559e+03],\n",
       "       [ 6.04248599e+02, -4.53870180e+01,  1.26220576e+01,\n",
       "        -7.84199612e+01,  1.96375474e+00, -3.69034959e+03,\n",
       "         9.15277111e+03, -6.80121429e+03,  2.31450376e+03,\n",
       "         5.76017672e+01, -2.00632196e+02],\n",
       "       [-6.88767257e+01, -1.04242066e+01, -1.78545409e+01,\n",
       "         5.22858210e+01, -2.52491383e+00, -5.11583502e+03,\n",
       "        -6.80121429e+03,  1.43112328e+04, -9.34520609e+03,\n",
       "         3.29683588e+03, -4.61642165e+02],\n",
       "       [-5.47611936e+02,  3.39610426e+01,  3.44605163e+01,\n",
       "        -1.85786499e+00,  2.69195514e-01,  6.06046581e+03,\n",
       "         2.31450376e+03, -9.34520609e+03,  1.05891217e+04,\n",
       "        -4.21399503e+03, -8.52339966e+02],\n",
       "       [ 6.50115515e+02, -3.89302874e+01,  3.12484613e+01,\n",
       "         1.90173697e+00,  1.23602502e+00, -2.27793195e+03,\n",
       "         5.76017672e+01,  3.29683588e+03, -4.21399503e+03,\n",
       "         4.92898238e+03, -3.03754128e+03],\n",
       "       [-2.12910702e+01,  3.93909503e+01, -4.30126911e+01,\n",
       "        -4.06171649e+00, -4.02332568e-01, -1.14494559e+03,\n",
       "        -2.00632196e+02, -4.61642165e+02, -8.52339966e+02,\n",
       "        -3.03754128e+03,  6.37754211e+03]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('distr_weighting_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_intervals = [confidence_interval(m, emp) for m, emp in zip(all_bootstrapped_moments, emp_moments)]\n",
    "bigger_confidence_intervals = [bigger_confidence_interval(m, emp) for m, emp in zip(all_bootstrapped_moments, emp_moments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.01250895315270514, -0.004972372250184702),\n",
       " (-0.10254115435603452, -0.004214243562520606),\n",
       " (-0.13326354929237721, -0.00011849649034352538),\n",
       " (0.1191595975547408, 0.302631324267812),\n",
       " (2.854538589493186, 7.092766197859348),\n",
       " (0.17148566039471264, 0.29024088013441146),\n",
       " (0.068621817622279, 0.2087810573343057),\n",
       " (0.011467242780874146, 0.14267080559615264),\n",
       " (-0.019033843604341717, 0.0925195398866297),\n",
       " (-0.020147409674270055, 0.11211077299605529),\n",
       " (-0.04900123713528164, 0.054204290890615035)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export conrfidence intervals of bootstrapped data\n",
    "with open('distr_bootstrapped_confidence_intervals.json', 'w') as fp:\n",
    "    json.dump(confidence_intervals, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I apply the cost function to the bootstrapped series to get a distribution of J-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_values = []\n",
    "for b in moments_b:\n",
    "    j_values.append(quadratic_loss_function(b, emp_moments, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export J-values of bootstrapped data\n",
    "with open('distr_bootstrapped_j_values.json', 'w') as fp:\n",
    "    json.dump(j_values, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
