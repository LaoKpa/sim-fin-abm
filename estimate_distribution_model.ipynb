{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "from matplotlib import style\n",
    "from pandas_datareader import data\n",
    "import random\n",
    "from SALib.sample import latin\n",
    "from functions.stylizedfacts import *\n",
    "import scipy.stats as stats\n",
    "from functions.evolutionaryalgo import *\n",
    "from pandas_datareader import data\n",
    "from functions.helpers import hurst, organise_data, div_by_hundred, discounted_value_cash_flow, find_horizon, calculate_npv\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate model\n",
    "Following the procedure presented by [Franke & Westerhoff (2012)](https://www.sciencedirect.com/science/article/pii/S0165188912000802).\n",
    "\n",
    "## 1 Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2008-12-31' #1933\n",
    "end_date = '2018-12-31'\n",
    "\n",
    "spy_nom_price = data.DataReader(\"SP500\", \n",
    "                       start=start_date, \n",
    "                       end=end_date, \n",
    "                       data_source='fred')[\"SP500\"].dropna()\n",
    "spy_nom_returns = spy_nom_price.pct_change()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Bootstrap data for both short and long-term moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_block_size = 250 # 250\n",
    "large_block_size = 625 # 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Small data blocks returns**\n",
    "For short term moments, I produce a bootstrapped series of 250 day (= 1 year) data blocks. This means that there are 25 unique blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_blocks = []\n",
    "for x in range(0, len(spy_nom_returns), small_block_size):\n",
    "    small_data_blocks.append(list(spy_nom_returns[x:x+small_block_size]))\n",
    "    \n",
    "# draw 5000 random series\n",
    "bootstrapped_small_series = []\n",
    "for i in range(5000):\n",
    "    sim_data = [random.choice(small_data_blocks) for _ in small_data_blocks]\n",
    "    sim_data2 = [j for i in sim_data for j in i]\n",
    "    bootstrapped_small_series.append(sim_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Large data blocks returns**\n",
    "\n",
    "For the longer moments, I produce a bootstrapped series of data blocks of 625 days. To accomodate this, I cut the data set with 250 observations, to 6000 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_blocks = []\n",
    "for x in range(0, len(spy_nom_returns), large_block_size): # used to be len(spy_nom_returns[:-250])\n",
    "    large_data_blocks.append(list(spy_nom_returns[x:x+large_block_size]))\n",
    "    \n",
    "# draw 5000 random series\n",
    "bootstrapped_long_series = []\n",
    "for i in range(5000):\n",
    "    sim_data = [random.choice(large_data_blocks) for _ in large_data_blocks]\n",
    "    sim_data2 = [j for i in sim_data for j in i]\n",
    "    bootstrapped_long_series.append(sim_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Choose moments\n",
    "\n",
    "For returns, I use the following moments **short-term moments**: \n",
    "\n",
    "1. mean first-order autocorrelation of the raw returns (no predictability),\n",
    "2. autocorrelations at lags t ¼ 1\n",
    "3. autocorrelations at lags t ¼ 5\n",
    "4. mean first-order autocorrelation of the of the absolute returns (volatility clustering),\n",
    "5. Kurtosis (fat tails), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_order_autocors = []\n",
    "mean_abs_autocor = []\n",
    "autocors1 = []\n",
    "autocors5 = []\n",
    "kurtoses = []\n",
    "for rets in bootstrapped_small_series:\n",
    "    first_order_autocors.append(autocorrelation_returns(rets, 25))\n",
    "    mean_abs_autocor.append(autocorrelation_abs_returns(rets, 25))\n",
    "    rets = pd.Series(rets)\n",
    "    autocors1.append(rets.autocorr(lag=1))\n",
    "    autocors5.append(rets.autocorr(lag=5))\n",
    "    kurtoses.append(kurtosis(rets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For long-term moments, I use the autocorrelation of returns for the with lags (10, 25, 50, 100, 150 and 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_abs_auto10 = []\n",
    "spy_abs_auto25 = []\n",
    "spy_abs_auto50 = []\n",
    "spy_abs_auto100 = []\n",
    "spy_abs_auto150 = []\n",
    "spy_abs_auto200 = []\n",
    "\n",
    "for rets in bootstrapped_long_series:\n",
    "    rets = pd.Series(rets)\n",
    "    spy_abs_auto10.append(rets.abs().autocorr(lag=10))\n",
    "    spy_abs_auto25.append(rets.abs().autocorr(lag=25))\n",
    "    spy_abs_auto50.append(rets.abs().autocorr(lag=50))\n",
    "    spy_abs_auto100.append(rets.abs().autocorr(lag=100))\n",
    "    spy_abs_auto150.append(rets.abs().autocorr(lag=150))\n",
    "    spy_abs_auto200.append(rets.abs().autocorr(lag=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bootstrapped_moments = [first_order_autocors,\n",
    "                            autocors1,\n",
    "                            autocors5,\n",
    "                            mean_abs_autocor,\n",
    "                            kurtoses,\n",
    "                            spy_abs_auto10,\n",
    "                            spy_abs_auto25,\n",
    "                            spy_abs_auto50,\n",
    "                            spy_abs_auto100,\n",
    "                            spy_abs_auto150,\n",
    "                            spy_abs_auto200\n",
    "                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the t-critical value*\n",
    "def confidence_interval(sample, emp_value):\n",
    "    \"\"\"Calculate confidence_interval in sample\"\"\"\n",
    "    z_critical = stats.norm.ppf(q = 0.99)\n",
    "    stdev = pd.Series(sample).std()\n",
    "    margin_of_error = z_critical * stdev\n",
    "    confidence_interval = (emp_value - margin_of_error, emp_value + margin_of_error)  \n",
    "    return confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_bootstraps_moments(full_series, bootstrap_number):\n",
    "    \"\"\"Get a vector with the moments of a specific bootstrap\"\"\"\n",
    "    return np.array([full_series[i][bootstrap_number] for i in range(len(full_series))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_moments = [np.mean(x) for x in all_bootstrapped_moments]\n",
    "moments_b = [get_specific_bootstraps_moments(all_bootstrapped_moments, n) for n in range(len(bootstrapped_long_series))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0085403959215959377,\n",
       " -0.059373447733413083,\n",
       " -0.046486740997376243,\n",
       " 0.1916297308552411,\n",
       " 4.6083558405710994,\n",
       " 0.21680205832111227,\n",
       " 0.11504999107652002,\n",
       " 0.066271071482962823,\n",
       " 0.011122122838318035,\n",
       " 0.028435498879957846,\n",
       " 0.0060635341640177974]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Estimate weighting matrix:\n",
    "\n",
    "Here, I follow [Franke & Westerhoff 2016](https://link.springer.com/article/10.1007/s11403-014-0140-6#Sec8) in that I use the inverse of the bootstrap estimate of the moment covariance matrix as my weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_moments = np.array([\n",
    "        autocorrelation_returns(spy_nom_returns, 25),\n",
    "        spy_nom_returns.autocorr(lag=1),\n",
    "        spy_nom_returns.autocorr(lag=5),\n",
    "        autocorrelation_abs_returns(spy_nom_returns, 25),\n",
    "        kurtosis(spy_nom_returns),\n",
    "        spy_nom_returns.abs().autocorr(lag=10),\n",
    "        spy_nom_returns.abs().autocorr(lag=25),\n",
    "        spy_nom_returns.abs().autocorr(lag=50),\n",
    "        spy_nom_returns.abs().autocorr(lag=100),\n",
    "        spy_nom_returns.abs().autocorr(lag=150),\n",
    "        spy_nom_returns.abs().autocorr(lag=200)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.91632942e-03,  -6.44109792e-02,  -5.17149408e-02,\n",
       "         2.15757804e-01,   4.99915089e+00,   2.29239806e-01,\n",
       "         1.36705815e-01,   8.99171488e-02,   3.97109985e-02,\n",
       "         4.56905198e-02,   3.40685479e-03])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent NA errors\n",
    "spy_abs_auto50 = list(pd.Series(spy_abs_auto50).fillna(0))\n",
    "spy_abs_auto100 = list(pd.Series(spy_abs_auto100).fillna(0))\n",
    "spy_abs_auto150 = list(pd.Series(spy_abs_auto150).fillna(0))\n",
    "spy_abs_auto200 = list(pd.Series(spy_abs_auto200).fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I estimate the moment covariance matrix of the bootstrapped data as: \n",
    "\n",
    "$\\hat{W} = \\frac{1}{B} \\sum{(m^b - \\hat{m})(m^b - \\hat{m})'}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hat = 1.0 / len(bootstrapped_long_series) * sum([np.dot(np.array([(mb - av_moments)]).transpose(), np.array([(mb - av_moments)])) for mb in moments_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And take the inverse so that \n",
    "\n",
    "$W = \\hat{W}^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.linalg.inv(W_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weighting matrix\n",
    "np.save('distr_weighting_matrix', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.40115835e+05,  -2.68094151e+04,  -1.54140820e+04,\n",
       "         -1.95997713e+04,   5.15715823e+02,  -6.90929363e+02,\n",
       "          2.83187460e+02,  -4.43014033e+01,  -7.25902562e+02,\n",
       "          3.92289690e+02,   7.85196438e+01],\n",
       "       [ -2.68094151e+04,   9.02487430e+03,  -4.15819453e+01,\n",
       "          5.88554858e+03,  -1.02567209e+02,   1.37733987e+02,\n",
       "         -1.31811278e+02,   6.94931439e+01,  -8.00463185e+01,\n",
       "          1.96732927e+01,   5.58659522e+00],\n",
       "       [ -1.54140820e+04,  -4.15819453e+01,   1.37453662e+03,\n",
       "          1.15527815e+02,  -9.31130052e+00,   1.09947142e+01,\n",
       "         -2.68475390e+01,   3.82182165e+01,   4.52543066e+01,\n",
       "         -6.47109626e+01,   5.55455107e+01],\n",
       "       [ -1.95997713e+04,   5.88554858e+03,   1.15527815e+02,\n",
       "          5.21197171e+03,  -1.14637237e+02,   1.55453511e+02,\n",
       "         -1.33940211e+02,   6.75360882e+01,  -6.39660820e+01,\n",
       "         -6.59512529e+00,   2.44945961e+01],\n",
       "       [  5.15715823e+02,  -1.02567209e+02,  -9.31130052e+00,\n",
       "         -1.14637237e+02,   3.95998180e+00,  -4.47785858e+00,\n",
       "          2.65254988e+00,  -1.24056874e+00,   1.15766142e+00,\n",
       "         -5.22544596e-01,   7.07733690e-01],\n",
       "       [ -6.90929363e+02,   1.37733987e+02,   1.09947142e+01,\n",
       "          1.55453511e+02,  -4.47785858e+00,   6.57106108e+03,\n",
       "         -7.37774660e+03,   2.40294452e+03,  -8.39031501e+02,\n",
       "         -1.71749483e+02,  -5.50211010e+02],\n",
       "       [  2.83187460e+02,  -1.31811278e+02,  -2.68475390e+01,\n",
       "         -1.33940211e+02,   2.65254988e+00,  -7.37774660e+03,\n",
       "          1.31343681e+04,  -7.43607703e+03,   2.83322646e+03,\n",
       "          1.26536082e+02,  -8.25043418e+02],\n",
       "       [ -4.43014033e+01,   6.94931439e+01,   3.82182165e+01,\n",
       "          6.75360882e+01,  -1.24056874e+00,   2.40294452e+03,\n",
       "         -7.43607703e+03,   7.22755210e+03,  -2.74232460e+03,\n",
       "          4.87299350e+02,   5.27180614e+02],\n",
       "       [ -7.25902562e+02,  -8.00463185e+01,   4.52543066e+01,\n",
       "         -6.39660820e+01,   1.15766142e+00,  -8.39031501e+02,\n",
       "          2.83322646e+03,  -2.74232460e+03,   4.49778066e+03,\n",
       "         -1.99835817e+03,  -6.66739073e+02],\n",
       "       [  3.92289690e+02,   1.96732927e+01,  -6.47109626e+01,\n",
       "         -6.59512529e+00,  -5.22544596e-01,  -1.71749483e+02,\n",
       "          1.26536082e+02,   4.87299350e+02,  -1.99835817e+03,\n",
       "          3.56462596e+03,  -1.97482673e+03],\n",
       "       [  7.85196438e+01,   5.58659522e+00,   5.55455107e+01,\n",
       "          2.44945961e+01,   7.07733690e-01,  -5.50211010e+02,\n",
       "         -8.25043418e+02,   5.27180614e+02,  -6.66739073e+02,\n",
       "         -1.97482673e+03,   3.88442260e+03]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('distr_weighting_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_intervals = [confidence_interval(m, emp) for m, emp in zip(all_bootstrapped_moments, emp_moments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export conrfidence intervals of bootstrapped data\n",
    "with open('distr_bootstrapped_confidence_intervals.json', 'w') as fp:\n",
    "    json.dump(confidence_intervals, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I apply the cost function to the bootstrapped series to get a distribution of J-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_values = []\n",
    "for b in moments_b:\n",
    "    j_values.append(quadratic_loss_function(b, emp_moments, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export J-values of bootstrapped data\n",
    "with open('distr_bootstrapped_j_values.json', 'w') as fp:\n",
    "    json.dump(j_values, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
